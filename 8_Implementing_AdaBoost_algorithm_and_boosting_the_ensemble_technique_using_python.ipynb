{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 8: Implementing the AdaBoost Algorithm and Boosting the Ensemble Technique Using Python\n",
        "\n",
        "## Aim\n",
        "To implement the AdaBoost algorithm using Python and demonstrate the boosting ensemble technique on a classification problem.\n",
        "\n",
        "## Objectives\n",
        "- Understand the AdaBoost algorithm and how it improves model performance.\n",
        "- Implement AdaBoost using Python's `sklearn` library.\n",
        "- Evaluate and visualize the performance of the ensemble model.\n",
        "\n",
        "## Tools Used\n",
        "- **scikit-learn**: For implementing AdaBoost and evaluating the model.\n",
        "- **Matplotlib** and **Seaborn**: For data visualization.\n",
        "\n",
        "## Implementation\n",
        "\n",
        "### Step 1: Import Libraries\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "```\n",
        "\n",
        "### Step 2: Create a Sample Dataset\n",
        "```python\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_classification(\n",
        "    n_samples=500, n_features=5, n_informative=3, n_redundant=0, n_classes=2, random_state=42\n",
        ")\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Visualize class distribution\n",
        "sns.countplot(x=y)\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Step 3: Initialize and Train the AdaBoost Classifier\n",
        "```python\n",
        "# Base estimator: Decision Tree with max depth of 1 (stump)\n",
        "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
        "\n",
        "# AdaBoost Classifier\n",
        "adaboost = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, learning_rate=1.0, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "adaboost.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "### Step 4: Evaluate the Model\n",
        "```python\n",
        "# Predict on test data\n",
        "y_pred = adaboost.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Class 0\", \"Class 1\"], yticklabels=[\"Class 0\", \"Class 1\"])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Step 5: Visualize Feature Importance\n",
        "```python\n",
        "# Feature importance\n",
        "feature_importances = adaboost.feature_importances_\n",
        "\n",
        "# Plot feature importance\n",
        "plt.bar(range(X.shape[1]), feature_importances, color='skyblue')\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.xlabel(\"Feature Index\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Step 6: Visualize Decision Boundaries\n",
        "```python\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# Decision boundary visualization\n",
        "def plot_decision_boundary(model, X, y):\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
        "                         np.arange(y_min, y_max, 0.01))\n",
        "\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8, cmap=ListedColormap(['#FFAAAA', '#AAAAFF']))\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap=ListedColormap(['#FF0000', '#0000FF']))\n",
        "    plt.title(\"Decision Boundary\")\n",
        "    plt.xlabel(\"Feature 1\")\n",
        "    plt.ylabel(\"Feature 2\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot decision boundary for the first two features\n",
        "plot_decision_boundary(adaboost, X[:, :2], y)\n",
        "```\n",
        "\n",
        "### Step 7: Summary and Observations\n",
        "```python\n",
        "print(\"\\nSummary:\")\n",
        "print(\"1. AdaBoost was implemented using DecisionTreeClassifier as the base estimator.\")\n",
        "print(\"2. The model achieved an accuracy of {:.2f}% on the test data.\".format(accuracy * 100))\n",
        "print(\"3. Visualizations, including feature importance and decision boundaries, were created to better understand the model's behavior.\")\n"
      ],
      "metadata": {
        "id": "qqnjogigEw2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ulR4ALlEx4P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}