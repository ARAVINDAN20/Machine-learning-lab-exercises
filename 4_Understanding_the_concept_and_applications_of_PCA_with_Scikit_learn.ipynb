{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 4: Understanding the Concept and Applications of PCA with Scikit-Learn\n",
        "\n",
        "## Aim\n",
        "To understand the concept of Principal Component Analysis (PCA) and apply it using Scikit-Learn for dimensionality reduction.\n",
        "\n",
        "## Objectives\n",
        "- Learn the theoretical foundation of PCA.\n",
        "- Perform PCA on a high-dimensional dataset.\n",
        "- Visualize the results and understand the reduction in dimensionality.\n",
        "\n",
        "## Tools Used\n",
        "- **Scikit-Learn**: For PCA implementation.\n",
        "- **Pandas** and **NumPy**: For data manipulation.\n",
        "- **Matplotlib** and **Seaborn**: For visualizations.\n",
        "\n",
        "## Implementation\n",
        "\n",
        "### Step 1: Import Libraries\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "```\n",
        "\n",
        "### Step 2: Load and Explore the Dataset\n",
        "```python\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "feature_names = iris.feature_names\n",
        "\n",
        "# Create a DataFrame for better readability\n",
        "df = pd.DataFrame(X, columns=feature_names)\n",
        "df['Target'] = y\n",
        "\n",
        "# Display the first few rows\n",
        "print(\"Original Dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Visualize the pairplot of the original features\n",
        "sns.pairplot(df, hue='Target', corner=True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Step 3: Standardize the Data\n",
        "```python\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"\\nStandardized Features:\")\n",
        "print(pd.DataFrame(X_scaled, columns=feature_names).head())\n",
        "```\n",
        "\n",
        "### Step 4: Apply PCA\n",
        "```python\n",
        "# Apply PCA to reduce dimensions\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Display explained variance ratio\n",
        "print(\"\\nExplained Variance Ratio:\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "\n",
        "# Create a DataFrame for PCA results\n",
        "pca_df = pd.DataFrame(X_pca, columns=['Principal Component 1', 'Principal Component 2'])\n",
        "pca_df['Target'] = y\n",
        "\n",
        "print(\"\\nPCA Transformed Dataset:\")\n",
        "print(pca_df.head())\n",
        "```\n",
        "\n",
        "### Step 5: Visualize the Results\n",
        "```python\n",
        "# Scatter plot of the first two principal components\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(\n",
        "    x='Principal Component 1',\n",
        "    y='Principal Component 2',\n",
        "    hue='Target',\n",
        "    palette='Set1',\n",
        "    data=pca_df\n",
        ")\n",
        "plt.title(\"PCA Result: First Two Principal Components\")\n",
        "plt.xlabel(\"Principal Component 1\")\n",
        "plt.ylabel(\"Principal Component 2\")\n",
        "plt.legend(title='Target', labels=iris.target_names)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Step 6: Evaluate PCA Impact\n",
        "```python\n",
        "# Print the cumulative explained variance ratio\n",
        "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
        "print(\"\\nCumulative Explained Variance Ratio:\")\n",
        "print(cumulative_variance)\n",
        "\n",
        "# Plot cumulative explained variance\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(range(1, len(cumulative_variance)+1), cumulative_variance, marker='o', linestyle='--')\n",
        "plt.title(\"Cumulative Explained Variance\")\n",
        "plt.xlabel(\"Number of Principal Components\")\n",
        "plt.ylabel(\"Cumulative Explained Variance\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Step 7: Summary and Observations\n",
        "```python\n",
        "print(\"\\nSummary:\")\n",
        "print(\"1. PCA reduced the dimensionality of the Iris dataset from 4 to 2 features while retaining most of the variance.\")\n",
        "print(\"2. The first two principal components explained {:.2f}% of the total variance.\".format(cumulative_variance[1] * 100))\n",
        "print(\"3. PCA helped visualize the high-dimensional data in 2D, enabling easier interpretation and analysis.\")\n"
      ],
      "metadata": {
        "id": "9v2BW0e4Ij3o"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jqLkxy3VIkYJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}